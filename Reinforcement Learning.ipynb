{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b108891e",
   "metadata": {},
   "source": [
    "## Installing required Dependencies\n",
    "### 1. Install Stable Baselines\n",
    "\n",
    "For additional information, refer to: https://stable-baselines3.readthedocs.io/en/master/guide/install.html\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "35a8d70b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: stable-baselines3[extra] in c:\\users\\prath\\anaconda3\\envs\\tf\\lib\\site-packages (1.7.0)\n",
      "Requirement already satisfied: pandas in c:\\users\\prath\\appdata\\roaming\\python\\python39\\site-packages (from stable-baselines3[extra]) (1.5.3)\n",
      "Requirement already satisfied: torch>=1.11 in c:\\users\\prath\\anaconda3\\envs\\tf\\lib\\site-packages (from stable-baselines3[extra]) (2.0.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\prath\\anaconda3\\envs\\tf\\lib\\site-packages (from stable-baselines3[extra]) (1.23.5)\n",
      "Requirement already satisfied: gym==0.21 in c:\\users\\prath\\anaconda3\\envs\\tf\\lib\\site-packages (from stable-baselines3[extra]) (0.21.0)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\prath\\anaconda3\\envs\\tf\\lib\\site-packages (from stable-baselines3[extra]) (3.6.3)\n",
      "Requirement already satisfied: cloudpickle in c:\\users\\prath\\appdata\\roaming\\python\\python39\\site-packages (from stable-baselines3[extra]) (2.2.1)\n",
      "Requirement already satisfied: importlib-metadata~=4.13 in c:\\users\\prath\\anaconda3\\envs\\tf\\lib\\site-packages (from stable-baselines3[extra]) (4.13.0)\n",
      "Requirement already satisfied: autorom[accept-rom-license]~=0.4.2 in c:\\users\\prath\\anaconda3\\envs\\tf\\lib\\site-packages (from stable-baselines3[extra]) (0.4.2)\n",
      "Requirement already satisfied: rich in c:\\users\\prath\\anaconda3\\envs\\tf\\lib\\site-packages (from stable-baselines3[extra]) (13.3.3)\n",
      "Requirement already satisfied: pillow in c:\\users\\prath\\anaconda3\\envs\\tf\\lib\\site-packages (from stable-baselines3[extra]) (9.4.0)\n",
      "Requirement already satisfied: psutil in c:\\users\\prath\\anaconda3\\envs\\tf\\lib\\site-packages (from stable-baselines3[extra]) (5.9.4)\n",
      "Requirement already satisfied: opencv-python in c:\\users\\prath\\anaconda3\\envs\\tf\\lib\\site-packages (from stable-baselines3[extra]) (4.7.0.68)\n",
      "Requirement already satisfied: tensorboard>=2.9.1 in c:\\users\\prath\\anaconda3\\envs\\tf\\lib\\site-packages (from stable-baselines3[extra]) (2.10.1)\n",
      "Requirement already satisfied: ale-py==0.7.4 in c:\\users\\prath\\anaconda3\\envs\\tf\\lib\\site-packages (from stable-baselines3[extra]) (0.7.4)\n",
      "Requirement already satisfied: tqdm in c:\\users\\prath\\anaconda3\\envs\\tf\\lib\\site-packages (from stable-baselines3[extra]) (4.64.1)\n",
      "Requirement already satisfied: importlib-resources in c:\\users\\prath\\appdata\\roaming\\python\\python39\\site-packages (from ale-py==0.7.4->stable-baselines3[extra]) (5.10.2)\n",
      "Requirement already satisfied: click in c:\\users\\prath\\appdata\\roaming\\python\\python39\\site-packages (from autorom[accept-rom-license]~=0.4.2->stable-baselines3[extra]) (8.1.3)\n",
      "Requirement already satisfied: requests in c:\\users\\prath\\anaconda3\\envs\\tf\\lib\\site-packages (from autorom[accept-rom-license]~=0.4.2->stable-baselines3[extra]) (2.28.2)\n",
      "Requirement already satisfied: AutoROM.accept-rom-license in c:\\users\\prath\\anaconda3\\envs\\tf\\lib\\site-packages (from autorom[accept-rom-license]~=0.4.2->stable-baselines3[extra]) (0.6.1)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\prath\\anaconda3\\envs\\tf\\lib\\site-packages (from importlib-metadata~=4.13->stable-baselines3[extra]) (3.12.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\users\\prath\\anaconda3\\envs\\tf\\lib\\site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (0.6.1)\n",
      "Requirement already satisfied: absl-py>=0.4 in c:\\users\\prath\\anaconda3\\envs\\tf\\lib\\site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (1.4.0)\n",
      "Requirement already satisfied: grpcio>=1.24.3 in c:\\users\\prath\\anaconda3\\envs\\tf\\lib\\site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (1.51.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\prath\\anaconda3\\envs\\tf\\lib\\site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (2.16.0)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in c:\\users\\prath\\anaconda3\\envs\\tf\\lib\\site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (3.19.6)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\prath\\anaconda3\\envs\\tf\\lib\\site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (1.8.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\prath\\anaconda3\\envs\\tf\\lib\\site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (3.4.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\prath\\anaconda3\\envs\\tf\\lib\\site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (2.2.2)\n",
      "Requirement already satisfied: wheel>=0.26 in c:\\users\\prath\\anaconda3\\envs\\tf\\lib\\site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (0.37.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\prath\\anaconda3\\envs\\tf\\lib\\site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (0.4.6)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\users\\prath\\anaconda3\\envs\\tf\\lib\\site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (65.6.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\prath\\anaconda3\\envs\\tf\\lib\\site-packages (from torch>=1.11->stable-baselines3[extra]) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\prath\\anaconda3\\envs\\tf\\lib\\site-packages (from torch>=1.11->stable-baselines3[extra]) (4.4.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\prath\\anaconda3\\envs\\tf\\lib\\site-packages (from torch>=1.11->stable-baselines3[extra]) (1.11.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\prath\\anaconda3\\envs\\tf\\lib\\site-packages (from torch>=1.11->stable-baselines3[extra]) (2.8.4)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\prath\\anaconda3\\envs\\tf\\lib\\site-packages (from torch>=1.11->stable-baselines3[extra]) (3.1.2)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\prath\\anaconda3\\envs\\tf\\lib\\site-packages (from matplotlib->stable-baselines3[extra]) (2.4.7)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\prath\\anaconda3\\envs\\tf\\lib\\site-packages (from matplotlib->stable-baselines3[extra]) (4.38.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\prath\\anaconda3\\envs\\tf\\lib\\site-packages (from matplotlib->stable-baselines3[extra]) (2.8.2)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\prath\\anaconda3\\envs\\tf\\lib\\site-packages (from matplotlib->stable-baselines3[extra]) (0.11.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\prath\\anaconda3\\envs\\tf\\lib\\site-packages (from matplotlib->stable-baselines3[extra]) (1.0.7)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\prath\\anaconda3\\envs\\tf\\lib\\site-packages (from matplotlib->stable-baselines3[extra]) (23.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\prath\\anaconda3\\envs\\tf\\lib\\site-packages (from matplotlib->stable-baselines3[extra]) (1.4.4)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\prath\\anaconda3\\envs\\tf\\lib\\site-packages (from pandas->stable-baselines3[extra]) (2022.7.1)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\prath\\anaconda3\\envs\\tf\\lib\\site-packages (from rich->stable-baselines3[extra]) (2.14.0)\n",
      "Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in c:\\users\\prath\\anaconda3\\envs\\tf\\lib\\site-packages (from rich->stable-baselines3[extra]) (2.2.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\prath\\anaconda3\\envs\\tf\\lib\\site-packages (from tqdm->stable-baselines3[extra]) (0.4.6)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\prath\\anaconda3\\envs\\tf\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->stable-baselines3[extra]) (4.9)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\prath\\anaconda3\\envs\\tf\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->stable-baselines3[extra]) (0.2.8)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\prath\\anaconda3\\envs\\tf\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->stable-baselines3[extra]) (5.3.0)\n",
      "Requirement already satisfied: six>=1.9.0 in c:\\users\\prath\\anaconda3\\envs\\tf\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->stable-baselines3[extra]) (1.16.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\prath\\anaconda3\\envs\\tf\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.9.1->stable-baselines3[extra]) (1.3.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\prath\\anaconda3\\envs\\tf\\lib\\site-packages (from markdown-it-py<3.0.0,>=2.2.0->rich->stable-baselines3[extra]) (0.1.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\prath\\anaconda3\\envs\\tf\\lib\\site-packages (from requests->autorom[accept-rom-license]~=0.4.2->stable-baselines3[extra]) (2022.12.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\prath\\anaconda3\\envs\\tf\\lib\\site-packages (from requests->autorom[accept-rom-license]~=0.4.2->stable-baselines3[extra]) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\prath\\anaconda3\\envs\\tf\\lib\\site-packages (from requests->autorom[accept-rom-license]~=0.4.2->stable-baselines3[extra]) (1.26.14)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\prath\\anaconda3\\envs\\tf\\lib\\site-packages (from requests->autorom[accept-rom-license]~=0.4.2->stable-baselines3[extra]) (3.0.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\prath\\anaconda3\\envs\\tf\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard>=2.9.1->stable-baselines3[extra]) (2.1.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\prath\\anaconda3\\envs\\tf\\lib\\site-packages (from sympy->torch>=1.11->stable-baselines3[extra]) (1.2.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\prath\\anaconda3\\envs\\tf\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.9.1->stable-baselines3[extra]) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\prath\\anaconda3\\envs\\tf\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.9.1->stable-baselines3[extra]) (3.2.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install stable-baselines3[extra]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be499923",
   "metadata": {},
   "source": [
    "## Import necessary Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "9fccdcca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gym\n",
    "import random\n",
    "import numpy as np\n",
    "from math import sqrt\n",
    "\n",
    "from gym import Env\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "from gym.spaces import Discrete, Box, Dict, Tuple, MultiBinary, MultiDiscrete"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aca1b9bb",
   "metadata": {},
   "source": [
    "## Building An Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1db2a5b1",
   "metadata": {},
   "source": [
    "### Network Parameters:\n",
    "1. Latency (MilliSeconds) (0 to 1500)\n",
    "2. Available Bandwidth (Mbs 0 to 3k) \n",
    "3. Signal Strength (-10 dB to -120 dB)\n",
    "4. Price per GB(INR) (2.5 to 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "21408c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def network_value(latency,bandwidth,signal_strength,price,required_latency,required_bandwidth):\n",
    "#     delta_latency = required_latency - latency\n",
    "#     delta_bandwidth = (bandwidth - required_bandwidth)**1.5\n",
    "#         self.networks = Tuple(tuple([self.network_stats.sample() for i in range(available_networks)]))\n",
    "#         self.networks = Tuple(tuple([self.network_stats.sample() for i in range(self.available_networks)]))\n",
    "# ----------------------------[Ignore Above Commented Code-Model Still in Development]------------------------\n",
    "\n",
    "def network_value(network_stats,application_stats):\n",
    "\n",
    "    delta_latency = application_stats[0] - network_stats[0]\n",
    "    delta_bandwidth = pow((network_stats[1] - application_stats[1]),3)\n",
    "\n",
    "    if delta_latency >= 0 and delta_bandwidth >= 0:\n",
    "        efficiency = 1/delta_latency*delta_bandwidth\n",
    "    else:\n",
    "        efficiency = -1/abs(delta_latency*delta_bandwidth)    \n",
    "    \n",
    "    return 0.6*efficiency + 0.25*(120 - abs(network_stats[2])) + 0.15*network_stats[3]\n",
    "\n",
    "class NetworkSelection(Env):\n",
    "    def __init__(self,available_networks:int):\n",
    "        self.cycle_length = 30 \n",
    "        self.available_networks = available_networks\n",
    "        self.action_space = Discrete(available_networks)\n",
    "        self.previous_state = -1\n",
    "        \n",
    "        \n",
    "        \n",
    "        self.application_requirement = Box(low=np.array([0,0]),high=np.array([500,3000])).sample()\n",
    "        self.network_stats = Box(low=np.array([0,0,-120,2.5]),high=np.array([1500,3000,-10,10]))\n",
    "        self.networks = [self.network_stats.sample() for i in range(self.available_networks)]\n",
    "\n",
    "        low = np.array([[0,0,-120,2.5] for i in range(available_networks)])\n",
    "        high = np.array([[1500,3000,-10,10] for i in range(available_networks)])\n",
    "        self.observation_space = Box(low=low,high=high)\n",
    "        \n",
    "    def step(self,action):\n",
    "        self.cycle_length -= 1\n",
    "        self.state = action\n",
    "        self.network_value = [network_value(i,self.application_requirement) for i in self.networks]\n",
    "        \n",
    "        if np.argmax(network_value) == action:\n",
    "            if action == self.previous_state:\n",
    "                reward = 20\n",
    "            else:\n",
    "                reward = 1\n",
    "        else:\n",
    "            ranking = 0\n",
    "            for value in self.network_value:\n",
    "                if value > self.network_value[action]:\n",
    "                    ranking += 1\n",
    "            reward = ranking*-10\n",
    "        \n",
    "        if self.cycle_length <= 0:\n",
    "            done = True\n",
    "        else:\n",
    "            done = False\n",
    "        self.previous_state = action\n",
    "        info = {}\n",
    "        return self.networks,reward,done,info\n",
    "        \n",
    "    def render(self):\n",
    "        pass\n",
    "    def reset(self):\n",
    "        self.cycle_length = 30\n",
    "        self.network_stats = Box(low=np.array([0,0,-120,2.5]),high=np.array([1500,3000,-10,10]))\n",
    "        self.networks = [self.network_stats.sample() for i in range(self.available_networks)]\n",
    "        self.application_requirement = Box(low=np.array([0,0]),high=np.array([500,3000])).sample()\n",
    "        return self.networks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c12d759a",
   "metadata": {},
   "source": [
    "## Model Testing on Random Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "02005236",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:1 Score:-1268\n",
      "Episode:2 Score:-1079\n",
      "Episode:3 Score:-1147\n",
      "Episode:4 Score:-1425\n",
      "Episode:5 Score:-1167\n",
      "Episode:6 Score:-886\n",
      "Episode:7 Score:-1420\n",
      "Episode:8 Score:-1387\n",
      "Episode:9 Score:-1278\n",
      "Episode:10 Score:-1187\n"
     ]
    }
   ],
   "source": [
    "# Model Performance on Random Input\n",
    "\n",
    "episodes = 10\n",
    "env = NetworkSelection(available_networks=10)\n",
    "for episode in range(1,episodes+1):\n",
    "    obs = env.reset()\n",
    "    done = False\n",
    "    score = 0\n",
    "    \n",
    "    while not done:\n",
    "        env.render() #set to PASS for now\n",
    "        action = env.action_space.sample()\n",
    "        obs, reward, done, info = env.step(action)\n",
    "        score += reward\n",
    "    print(f'Episode:{episode} Score:{score}')\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "098ef3bd",
   "metadata": {},
   "source": [
    "## Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "a32f6296",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_path_ppo = os.path.join('Training','Logs','PPO')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "c2de6ce4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    }
   ],
   "source": [
    "model_ppo = PPO('MlpPolicy',env,verbose=1,tensorboard_log=log_path_ppo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "6e69f77b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to Training\\Logs\\PPO\\PPO_1\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 30        |\n",
      "|    ep_rew_mean     | -1.19e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 218       |\n",
      "|    iterations      | 1         |\n",
      "|    time_elapsed    | 9         |\n",
      "|    total_timesteps | 2048      |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | -1.2e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 218         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 18          |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008878977 |\n",
      "|    clip_fraction        | 0.0535      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.3        |\n",
      "|    explained_variance   | 0.000141    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 8.2e+04     |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.0133     |\n",
      "|    value_loss           | 1.62e+05    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 30           |\n",
      "|    ep_rew_mean          | -1.13e+03    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 219          |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 28           |\n",
      "|    total_timesteps      | 6144         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0064130584 |\n",
      "|    clip_fraction        | 0.0481       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.29        |\n",
      "|    explained_variance   | -6.85e-05    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 8.08e+04     |\n",
      "|    n_updates            | 20           |\n",
      "|    policy_gradient_loss | -0.0105      |\n",
      "|    value_loss           | 1.63e+05     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | -1.09e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 234         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 34          |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006902674 |\n",
      "|    clip_fraction        | 0.0589      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.27       |\n",
      "|    explained_variance   | -1.66e-05   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 6.31e+04    |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.013      |\n",
      "|    value_loss           | 1.32e+05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | -1.05e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 41          |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010296484 |\n",
      "|    clip_fraction        | 0.0649      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.25       |\n",
      "|    explained_variance   | -6.71e-05   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 7.74e+04    |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.0153     |\n",
      "|    value_loss           | 1.29e+05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | -1.04e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 252         |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 48          |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009382744 |\n",
      "|    clip_fraction        | 0.0738      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.22       |\n",
      "|    explained_variance   | -1.74e-05   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 6.47e+04    |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.0146     |\n",
      "|    value_loss           | 1.24e+05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | -939        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 260         |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 55          |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010147823 |\n",
      "|    clip_fraction        | 0.0941      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.16       |\n",
      "|    explained_variance   | 1.76e-05    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 5.24e+04    |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.0179     |\n",
      "|    value_loss           | 1.08e+05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | -823        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 260         |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 62          |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012066498 |\n",
      "|    clip_fraction        | 0.137       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.08       |\n",
      "|    explained_variance   | 2.27e-05    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.02e+04    |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.0223     |\n",
      "|    value_loss           | 9.2e+04     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | -749        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 255         |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 72          |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014426196 |\n",
      "|    clip_fraction        | 0.192       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.93       |\n",
      "|    explained_variance   | -9.89e-06   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.85e+04    |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.0254     |\n",
      "|    value_loss           | 6.71e+04    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30         |\n",
      "|    ep_rew_mean          | -570       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 260        |\n",
      "|    iterations           | 10         |\n",
      "|    time_elapsed         | 78         |\n",
      "|    total_timesteps      | 20480      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01600045 |\n",
      "|    clip_fraction        | 0.317      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.77      |\n",
      "|    explained_variance   | 3.22e-06   |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 2.53e+04   |\n",
      "|    n_updates            | 90         |\n",
      "|    policy_gradient_loss | -0.0392    |\n",
      "|    value_loss           | 5.66e+04   |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.ppo.ppo.PPO at 0x19223669fa0>"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_ppo.learn(total_timesteps=20000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb2ad855",
   "metadata": {},
   "source": [
    "## Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "82a55487",
   "metadata": {},
   "outputs": [],
   "source": [
    "ppo_mlp_path = os.path.join('Training','SavedModels','PPOv1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "fc00cecc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prath\\anaconda3\\envs\\tf\\lib\\site-packages\\stable_baselines3\\common\\save_util.py:278: UserWarning: Path 'Training\\SavedModels' does not exist. Will create it.\n",
      "  warnings.warn(f\"Path '{path.parent}' does not exist. Will create it.\")\n"
     ]
    }
   ],
   "source": [
    "model_ppo.save(ppo_mlp_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "a82ea3fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "del model_ppo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "59a7b666",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    }
   ],
   "source": [
    "model_ppo = PPO.load(ppo_mlp_path,env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "c031f629",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(600.0, 0.0)"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Note: cannot evaluate as Len of Episode is Fixed\n",
    "\n",
    "evaluate_policy(model_ppo,env,n_eval_episodes=200,render=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "5ffe957e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:1 Score:-343\n",
      "Episode:2 Score:-425\n",
      "Episode:3 Score:-273\n",
      "Episode:4 Score:-135\n",
      "Episode:5 Score:-622\n",
      "Episode:6 Score:-63\n",
      "Episode:7 Score:-184\n",
      "Episode:8 Score:-440\n",
      "Episode:9 Score:-743\n",
      "Episode:10 Score:-302\n"
     ]
    }
   ],
   "source": [
    "# Model Performance after Training\n",
    "\n",
    "episodes = 10\n",
    "for episode in range(1,episodes+1):\n",
    "    obs = env.reset()\n",
    "    done = False\n",
    "    score = 0\n",
    "    \n",
    "    while not done:\n",
    "        env.render() #set to PASS for now\n",
    "        action, _ = model_ppo.predict(obs)\n",
    "        obs, reward, done, info = env.step(action)\n",
    "        score += reward\n",
    "    print(f'Episode:{episode} Score:{score}')\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64f882c2",
   "metadata": {},
   "source": [
    "## Viewing Logs in TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b64e5dc5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfodfile",
   "language": "python",
   "name": "tfodfile"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
